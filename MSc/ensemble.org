#+TITLE:  Ensemble Methods
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Params {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \pol {\pi}
#+LaTeX_HEADER: \newcommand \Pols {\Pi}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Bels {\mathcal{B}}
#+LaTeX_HEADER: \newcommand \Unif {\textrm{Unif}}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Mult {\textrm{Mult}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Dir {\textrm{Dir}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_HEADER: \newcommand \Simplex {\mathbb{\Delta}}
#+LaTeX_HEADER: \newcommand \pn {\param^{(n)}}
#+LaTeX_HEADER: \newcommand \pnn {\param^{(n+1)}}
#+LaTeX_HEADER: \newcommand \pnp {\param^{(n-1)}}
#+LaTeX_HEADER: \usepackage[bbgreekl]{mathbbol}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:2
#+OPTIONS: toc:nil
* Ensemble Methods
** Bagging
*** Algorithm
- Input: Data $D$, bags $K$, base learner $\lambda$
- For $k = 1, \ldots, K$
-- Sample \alert{with replacement} $D_k \sim \Unif(D)$
-- Obtain predictor $\pi_k = \lambda(D_k)$.
- Return $\{\pi_k\}$

*** The bagged predictor
\[
\pi = f\left(\sum_k \pi_k\right)
\]
** Bagging classifiers
*** Classification setting
- Weak learner $\lambda : D \to \Pi$
- Base hypotheses $\pi_k : X \to \{-1,1\}$
with
\[
\pi_k = \lambda(D_k), \qquad D_k \sim D
\]
- Aggregate hypothesis
\[
\pi(x) = \sgn\left(\sum_{k=1}^K \pi_k(x)\right)
\]
*** PAC property
For any $\delta \in (0,1)$, and any $\pi^* : X \to \{-1, 1\}$ and a hypothesis class $\Pols$ with with VC dimension $d$, for $T$ data points, and $K \in [0.02T, T]$ bootstrap samples, then
\[
\mathbb{L} \in O\left(\frac{1}{T}[d + \ln(1/\delta)]\right), \qquad \textrm{w.p.} 1 - \delta.
\]
** Sub-sample-and-aggregate
*** Algorithm
    - Input: Data $D$, number of experts $K$, base learner $\lambda$
    - For $k = 1, \ldots, K$
    -- Sample \alert{without replacement} $D_k \sim \Unif(D)$
    -- Obtain predictor $\pi_k = \lambda(D_k)$.
    - Return $\{\pi_k\}$

*** The aggregated predictor
    \[
    \pi =  f\left(\pi_1, \ldots, \pi_k\right)
    \]




