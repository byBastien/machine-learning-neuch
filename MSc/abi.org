#+TITLE:  Approximate Bayesian Inference
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Params {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \pol {\pi}
#+LaTeX_HEADER: \newcommand \Pols {\Pi}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Bels {\mathcal{B}}
#+LaTeX_HEADER: \newcommand \Unif {\textrm{Unif}}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Mult {\textrm{Mult}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Dir {\textrm{Dir}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_HEADER: \newcommand \Simplex {\mathbb{\Delta}}
#+LaTeX_HEADER: \newcommand \pn {\param^{(n)}}
#+LaTeX_HEADER: \newcommand \pnn {\param^{(n+1)}}
#+LaTeX_HEADER: \newcommand \pnp {\param^{(n-1)}}
#+LaTeX_HEADER: \usepackage[bbgreekl]{mathbbol}
#+LaTeX_HEADER: \tikzstyle{utility}=[diamond,draw=black,draw=blue!50,fill=blue!10,inner sep=0mm, minimum size=8mm]
#+LaTeX_HEADER: \tikzstyle{select}=[rectangle,draw=black,draw=blue!50,fill=blue!10,inner sep=0mm, minimum size=6mm]
#+LaTeX_HEADER: \tikzstyle{hidden}=[dashed,draw=black,fill=red!10]
#+LaTeX_HEADER: \tikzstyle{RV}=[circle,draw=black,draw=blue!50,fill=blue!10,inner sep=0mm, minimum size=6mm]
#+LaTeX_CLASS_OPTIONS: [smaller]
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:2
#+OPTIONS: toc:nil
* Approximate Bayesian inference
** Approximate Bayesian inference
*** The General problem
- Observations $D$.
- Nuisance variables $z$.
- Unknown parameter $\param$.
- Direct calculation of any of these terms can be infeasible:
\[
\bel(\param \mid D) = \frac{P_\param(D) \bel(\param)}{\sum_{\param'} P_{\param'}(D) \bel(\param')},
\qquad
P_\param(D) = \sum_z P_\param(D, z).
\]
*** Common methods
- Monte Carlo 
- Variational Bayes
- Approximate Bayesian Computation (ABC)
- Stochastic Variational Inference

* Monte-Carlo Methods
** Basic sampling theory

*** Inversion sampler
$F(u) = \Pr(x \geq u) = P(\{\omega : x(\omega) \geq u\})$ is the CDF of $x$.
- Sample $u$ uniformly in $[0,1]$
- Set $x = F^{-1}(u)$.

*** Rejection Sampler
- Input: Threshold $\epsilon$, distribution $Q$
- Repeat:
- $\hat{x} \sim Q$.
- $u \sim \Unif[0,1]$
- Until $u \leq P(\hat{x}) / \epsilon Q(\hat{x})$.
- Return $\hat{x}$

*** Notes
- Useful for sampling from a known distribution $P$.
- Indirectly useful from sampling from unknown distributions.


** Monte-Carlo sampling
\[
\bel(B \mid D) = \frac{\int_{B} P_\param(D) d \bel(\param)}{\int_{\Params} P_{\param'}(D) \bel(\param')}
\]
We can approximate the integrals by sampling from the prior $\bel$:
\[
\int_{B} P_\param(D) d \bel(\param)
\approx
\frac{1}{N}
\sum_{n=1}^N \ind{\pn \in B} P_{\pn}(D),
\qquad \pn \sim \bel.
\]
- Sampling from the prior is inefficient.
- The estimator has high bias and variance.
- So, we can use Markov Chain Monte Carlo. This lets us sample a
  sequence $\pn$ which \alert{converges asymptotically} to $\bel(\pn |
  D)$.


** Markov Chain Monte Carlo

*** MCMC for posterior sampling
- Form a Markov chain $P(\pnn \mid \pn, D)$

*** MCMC for other latent variables
- Form a Markov chain $P(z^{(n+1)} \mid z^{(n)}, D)$

** Metropolis-Hastings
*** Algorithm (symmetric version)
- Input: Proposal distribution $Q(x | x') = Q(x' | x)$
- At time $n$:
- $\hat{x} \sim Q(x | x^{(n)})$
- w.p. $P(\hat{x}) / P(x^{(n)})$, $x^{(n+1)} = \hat{x}$ else $x^{(n+1)} = x^{(n)}$
*** Application to posterior sampling:
The denominator cancels out, leading to:
\[
\frac{\bel(\param' \mid D)}{\bel(\param \mid D)}
= 
\frac{P_{\param'}(D) \bel(\param')}{P_{\param}(D) \bel(\param)}
\]
The only question is which proposal to use.
** Metropolis-Hastings
*** Algorithm
- Input: Proposal distribution $Q(x | x')$ satisfying detailed balance, likelihood $P$.
- At time $n$:
- $\hat{x} | x^{(n)} \sim Q(x | x^{(n)})$
- With probability
  \[
  \frac{P(\hat{x}) Q( x^{(n)} | \hat{x} )}{P(x^{(n)}) Q(\hat{x} | x^{(n)})},
  \]
  set $x^{(n+1)} = \hat{x}$
- Otherwise $x^{(n+1)} = x^{(n)}$
*** Application to posterior sampling:
The $\Pr_\bel(D)$ term cancels out, leading to:
\[
\frac{\bel(\param' \mid D) Q(\param \mid \param') }{\bel(\param \mid D)  Q(\param' \mid \param)}
= 
\frac{P_{\param'}(D) \bel(\param')  Q(\param \mid \param')}{P_{\param}(D) \bel(\param)  Q(\param' \mid \param)}
\]

** M-H Theory
*** Stationary distribution
The Markov chain defined by the M-H algorithm must have a unique stationary distribution
\[
\sigma = \sigma \vectorsym{P},
\]
where $\vectorsym{P}$ is the transition kernel of the chain with
\[
P_{ij} = \Pr(x^{(n+1)} = j \mid x^{(n)} = i).
\]
In addition, $\lim_{n \to \infty} \vectorsym{P}^k = \vectorsym{1} \sigma$.
*** Sufficient conditions
- If the transition kernel satisfies \alert{detailed balance}:
\[
P(x' | x) \sigma(x) = P(x | x') \sigma(x')
\]
then $\sigma(x)$ is a stationary distribution.
- If the Markov chain is \alert{ergodic} then there is a unique $\sigma$.
** The Gibbs sampler
This is used when we need to sample over only some variables $z_1, \ldots, z_k$, given some fixed variables $x$.
*** General algorithm
- Input: Factors $P(z_k \mid z_1, \ldots z_{k-1}, z_{k+1}, \ldots, z_K, x)$
- For $n \in [N]$:
- For $k \in [K]$:
  $z^{(n)}_k \sim P(z_k \mid z^{(n)}_1, \ldots z^{(n)}_{k-1}, z^{(n-1)}_{k+1}, \ldots, z^{(n-1)}_K, x)$
*** Application to posterior sampling with latent variables:
Latent variable $z$, parameter $\param$.
- Until convergence:
- $\param^{(n)} \sim P(\param \mid z^{(n-1)}, x)$
- $z^{(n)} \sim  P(z \mid \param^{(n)}, x)$
** ABC: Approximate Bayesian Computation
*** When to use
- When we can sample from $P_\param(D)$.
- When we cannot calculate $P_\param(D)$.
*** A metric $\rho$ over datasets
- $\rho(D, D')$ is distance between datasets.
- We can use that to define a rejection sampler
*** ABC Rejection Sampling
- \textbf{Input}: $\epsilon > 0$.
- Sample $\param' \sim \bel(\param)$
- Sample $D' \sim P_{\param'}$.
- If $\rho(D, D') \leq \epsilon$, accept $\param'$
*** Theorem
If $\rho(D, D') = \|f(D) - f(D')\|$ and $f$ is a \alert{sufficient statistic} and $\epsilon = 0$ then ABC Rejection Sampling is exact.

* Packages
** Multi-platform
- STAN
- BUGS
** Python
- PyMC3
- TensorFlow Probability
- \alert{PyStan}
- \alert{Pyro} (Torch)
